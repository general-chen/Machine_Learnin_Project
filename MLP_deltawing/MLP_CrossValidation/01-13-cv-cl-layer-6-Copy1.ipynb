{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc85384-5338-44b5-8cca-0a23ede41570",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This code is a cross-validation for CL\n",
    "- no filter for all CL, CD\n",
    "- bessel filter for CP |  bessel filter; $w_n = 0.01$, the frequence based on Nyquist rate (=sample_freq/2) is: $0.01*1000/2=5$\n",
    "- no standardization; no normalization\n",
    "- with L2\n",
    "- activation func: PReLU\n",
    "- No CP'(t), CP''(t) !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a4dee-08ed-4cc7-97a7-c4aadbccc951",
   "metadata": {},
   "source": [
    "# Define which task to run:\n",
    "- task  = ['predict', 'cross_validation']\n",
    "    - 'cross_validation': for cross validation; has 7 folds\n",
    "    - 'predict': for test using parameters chose by cross validation; has 1 fold --> fold8\n",
    "- force = ['CL', 'CD']\n",
    "- filt  = ['bessel', 'no filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11df159-4433-4a6d-884b-50f11da2a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'cross_validation' \n",
    "force = 'CL'     \n",
    "filt = 'bessel'  # only for cp; no cl or cd filter\n",
    "\n",
    "if task == 'cross_validation':\n",
    "    folds = 7\n",
    "elif task == 'predict':\n",
    "    folds = 1\n",
    "else:\n",
    "    print('Error. Please define your task.') \n",
    "print('Define the task complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fcee2-47f8-4776-a587-d61f56472cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics, regularizers\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 使用第二，三块GPU \"2,3\"（从0开始）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98543e-3225-4f99-822e-691f0c983d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.signal import bessel\n",
    "from scipy.signal import filtfilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab674201-fae0-4446-8418-fc8b41e7a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data\n",
    "history_all = {}\n",
    "predictions = {}\n",
    "\n",
    "# folder path\n",
    "data_path = 'gust_dataframe.xlsx'\n",
    "\n",
    "# read the excel data\n",
    "gust_origin = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3660c-9326-43eb-a986-cf97278989c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gust_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48e9af-2019-41d3-ad3a-8fe202dbe203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first column as index, i.e. set case_nn as index, for convenience\n",
    "gust_origin.set_index('case_number', inplace=True)\n",
    "print(gust_origin.shape)\n",
    "# check the first 5 columns\n",
    "gust_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca46c3-539b-4355-bf59-d79ffebe6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bessel filter for every column; only filt CP\n",
    "if filt == 'bessel':\n",
    "    \n",
    "    gust_index   = gust_origin.index\n",
    "    gust_column  = gust_origin.columns\n",
    "    gust_no_filter = np.zeros((gust_index.nunique(),len(gust_origin.loc[['case_01']]),len(gust_origin.columns))) # (32,2500,18)\n",
    "    gust_filter    = np.zeros((gust_index.nunique(),len(gust_origin.loc[['case_01']]),len(gust_origin.columns)))\n",
    "    case_all_no = (np.linspace(0,31,32)).astype(int)\n",
    "    b, a = bessel(8, 0.01) # define the bessel filter; 8 is the filter order; 0.01 is the W_n (between 0 to 1)\n",
    "    \n",
    "    for i in case_all_no:      # i is the case number\n",
    "        case_numer = 'case_' + str(i+1).zfill(2)\n",
    "        gust_no_filter[i] = gust_origin.loc[[case_numer]].to_numpy()\n",
    "        for j in range(len(gust_origin.columns)-2):       # j is the CP and CL CD number\n",
    "            gust_filter[i][:,j] = filtfilt(b, a, gust_no_filter[i][:,j]) # bessel filter for cp\n",
    "        gust_filter[i][:,len(gust_origin.columns)-2] = gust_no_filter[i][:,len(gust_origin.columns)-2]  # no filter for CL\n",
    "        gust_filter[i][:,len(gust_origin.columns)-1] = gust_no_filter[i][:,len(gust_origin.columns)-1]  # no filter for CD\n",
    "    gust = pd.DataFrame(data=np.concatenate(gust_filter,axis=0), index=gust_index, columns=gust_column)\n",
    "    \n",
    "elif filt == 'no filter':\n",
    "    gust = gust_origin\n",
    "    \n",
    "else:\n",
    "    print('Error. Please define your filter.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5309f75-f04f-4e5d-b3b1-b768710d9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gust\n",
    "gust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfee08-0f29-4cab-9881-f26a15494d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check filter result\n",
    "if filt == 'bessel':\n",
    "    ii = 16 # case to show\n",
    "    case_to_show = 'case_' + str(ii+1).zfill(2)\n",
    "    cp_to_show   = 1\n",
    "    fig,ax = plt.subplots(figsize=(16,5))\n",
    "    ax.plot(gust_origin.loc[[case_to_show]].to_numpy()[:,cp_to_show],label='gust_no_filter')\n",
    "    ax.plot(gust.loc[[case_to_show]].to_numpy()[:,cp_to_show],label='gust_filter')\n",
    "    ax.legend()\n",
    "elif filt == 'no filter':\n",
    "    print('No filter. No compare.')\n",
    "else:\n",
    "    print('Error. Please define your filter.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de407df-aaaf-4880-90e2-1ada3b4fc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gust[['Cp1_t']].to_numpy()[0:2500,0])\n",
    "plt.plot(gust[['CL']].to_numpy()[0:2500,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02190f-a0e2-4fdf-8a3b-bf437fdf31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve CP = 16 columns in total\n",
    "# simply drop CL and CD, then the rest is CP\n",
    "CP = gust.drop(['CL','CD'],axis=1, inplace=False)\n",
    "CP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dedc6-1052-4edf-85f2-d196f1386986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve CL and CD\n",
    "CL = gust[['CL']]\n",
    "CD = gust[['CD']]\n",
    "CL.head()\n",
    "CD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e93ee-54ad-45bc-8b16-60c83628b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve for 8 different folds\n",
    "# read the split .txt file; the number means the cases for test\n",
    "split_path = 'delta_wing_32cases_split_random.txt'\n",
    "with open(split_path, 'r') as file1:    \n",
    "    fold_split = file1.read().splitlines()       # split by \\n\n",
    "fold_split = fold_split[1:] # drop the head line\n",
    "for i in range(8):\n",
    "    fold_split[i] = fold_split[i][9:].split()    # split by space; the number starts from 10th character.\n",
    "    for j in range(4):\n",
    "        fold_split[i][j] = int(fold_split[i][j]) # convert string to int\n",
    "fold_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c371b-62bf-4bfc-b466-8c83b9a0f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 32 case number\n",
    "case_all_num = np.arange(gust.index.nunique()) + 1\n",
    "print(case_all_num)\n",
    "print(case_all_num.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8160d8-c789-4114-af55-eb91d37144ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the case number for train and test cases;\n",
    "if task == 'cross_validation':\n",
    "    train_case = [ [0]*24 for _ in range(folds) ] # initialize 2d list; list for 'case_nn'\n",
    "    test_case  = [ [0]*4 for _ in range(folds) ]\n",
    "    # find case number for cross validation folds: fold1~fold7\n",
    "    for i in range(folds): \n",
    "        train_case_temp = np.setdiff1d( case_all_num, np.concatenate((fold_split[i], fold_split[-1]))) \n",
    "        # drop test case and the last one (which is for fold 8 , final test)\n",
    "        test_case_temp  = fold_split[i]\n",
    "\n",
    "        # conbine to 'case_nn' sample for train and test case; prepare for next step\n",
    "        for j in range(len(train_case_temp)):\n",
    "            train_case[i][j] = 'case_' + str(train_case_temp[j]).zfill(2)\n",
    "        for k in range(len(test_case_temp)):\n",
    "            test_case[i][k]  = 'case_' + str(test_case_temp[k]).zfill(2)\n",
    "            \n",
    "elif task == 'predict': \n",
    "    train_case = [ [0]*28 for _ in range(folds) ] # initialize 2d list; list for 'case_nn'\n",
    "    test_case  = [ [0]*4 for _ in range(folds) ]\n",
    "    # find case number for test fold: fold8  \n",
    "    train_case_temp = np.setdiff1d(case_all_num, fold_split[-1])\n",
    "    test_case_temp  = fold_split[-1]\n",
    "    for jj in range(len(train_case_temp)):\n",
    "        train_case[-1][jj] = 'case_' + str(train_case_temp[jj]).zfill(2)\n",
    "    for kk in range(len(test_case_temp)):\n",
    "        test_case[-1][kk]  = 'case_' + str(test_case_temp[kk]).zfill(2)\n",
    "\n",
    "else:\n",
    "    print('Error. Please define your task.')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210977a4-2397-4c01-a2bd-86b7cbeb640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_case[0])\n",
    "print(test_case[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00903cc-e920-4325-b94e-f89cd8a9f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task)\n",
    "print(force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668a40d-e195-4139-baf7-3692134e6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  prepare for train and test data sets\n",
    "if task == 'cross_validation':\n",
    "    F_train_rec = np.zeros([folds,60000,1]) # 24*2500 = 60000\n",
    "    F_test_rec  = np.zeros([folds,10000,1])  # 4*2500  = 10000\n",
    "    P_train_rec = np.zeros([folds,60000,16])\n",
    "    P_test_rec  = np.zeros([folds,10000,16])\n",
    "\n",
    "    for i in range(folds): # 7 folds for training, the last one is for test, not retrieve here, since this is for training\n",
    "        if force == 'CL':\n",
    "            F_train_rec[i] = CL.loc[train_case[i]].to_numpy()\n",
    "            F_test_rec[i]  = CL.loc[test_case[i]].to_numpy()\n",
    "        elif force == 'CD':\n",
    "            F_train_rec[i] = CD.loc[train_case[i]].to_numpy()\n",
    "            F_test_rec[i]  = CD.loc[test_case[i]].to_numpy()\n",
    "        else:\n",
    "            print('Error. Please define force.')\n",
    "\n",
    "        P_train_rec[i] = CP.loc[train_case[i]].to_numpy()\n",
    "        P_test_rec[i]  = CP.loc[test_case[i]].to_numpy()\n",
    "\n",
    "elif task == 'predict':\n",
    "    F_train_rec = np.zeros([folds,70000,1]) # 28*2500 = 70000\n",
    "    F_test_rec  = np.zeros([folds,10000,1])  # 4*2500  = 10000\n",
    "    P_train_rec = np.zeros([folds,70000,16])\n",
    "    P_test_rec  = np.zeros([folds,10000,16])\n",
    "    \n",
    "    if force == 'CL':\n",
    "        F_train_rec[0] = CL.loc[train_case[0]].to_numpy()\n",
    "        F_test_rec[0]  = CL.loc[test_case[0]].to_numpy()\n",
    "    elif force == 'CD':\n",
    "        F_train_rec[0] = CD.loc[train_case[0]].to_numpy()\n",
    "        F_test_rec[0]  = CD.loc[test_case[0]].to_numpy()\n",
    "    else:\n",
    "        print('Error. Please define force.')\n",
    "\n",
    "    P_train_rec[0] = CP.loc[train_case[0]].to_numpy()\n",
    "    P_test_rec[0]  = CP.loc[test_case[0]].to_numpy()\n",
    "    \n",
    "else:\n",
    "    print('Error. Please define your task.')\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014ee0d-843f-40ab-ba95-72c682d74b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' begin training '''\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.layers import LeakyReLU, PReLU \n",
    "\n",
    "num_neuron = [16, 24, 32, 40, 48, 56, 64, 72]\n",
    "num_layer  = [6]#[1,2,3,4,5,6,7,8]\n",
    "epoch_total = 200 # 200 #l1_n8:193; l1_n16:196; l1_n24:189; l1_n32:166\n",
    "weight_decay = 0 # 5e-4 # l2 regularization hyperparameter | no L2, as there is noise in CL\n",
    "learn_rate   = 1e-5 # 1e-3\n",
    "batch_how    = 200  # 200\n",
    "\n",
    "# define callback: predict on each epoch\n",
    "class prediction_for_each_epoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch_predictions = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_predictions.append(model.predict(P_test))\n",
    "        \n",
    "# record start time\n",
    "starttime = datetime.datetime.now()\n",
    "# sleep 2 seconds\n",
    "time.sleep(0)\n",
    "\n",
    "for i in num_neuron: # define the neurons\n",
    "    \n",
    "    for j in num_layer: # define the hidden layers\n",
    "        \n",
    "        for k in range(folds): # start loop; if folds=7, then do cross validation; if folds=1, then, do predict\n",
    "            \n",
    "            print('start fold'+str(k+1).zfill(2)+' | layer'+str(j)+' |neuron'+str(i))\n",
    "            \n",
    "            predictions[k,i,j]=prediction_for_each_epoch()\n",
    "            \n",
    "            F_train = F_train_rec[k][:,:]   # change to 2d for training\n",
    "            F_test  = F_test_rec[k][:,:]\n",
    "            P_train = P_train_rec[k][:,:]\n",
    "            P_test  = P_test_rec[k][:,:]\n",
    "            '''load data done'''\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            neuron = i\n",
    "\n",
    "            # ##### build the model #####\n",
    "            \n",
    "            # Input layer, no activation for input layer, no L2\n",
    "            model.add(Input(shape=(16,)))  \n",
    "            \n",
    "            # Hidden layer\n",
    "            for jj in range(j):       \n",
    "                model.add(Dense(neuron, kernel_regularizer=regularizers.l2(weight_decay))) \n",
    "                model.add(PReLU())\n",
    "            \n",
    "            # Output layer => output dimension = 1 since it is regression problem; no activation for output layer\n",
    "            model.add(Dense(1, activation = 'linear', kernel_regularizer=regularizers.l2(weight_decay)))   \n",
    "            \n",
    "            model.summary()\n",
    "            \n",
    "            adam = optimizers.Adam(learning_rate = learn_rate)    \n",
    "            \n",
    "            model.compile(optimizer = adam, loss = 'mean_squared_error')#, metrics = ['mean_absolute_error'])    \n",
    "            # for regression problems, mean squared error (MSE) is often employed; \n",
    "            # do not use 'accuracy', as this is used for classification problem\n",
    "            \n",
    "            # # load model, only for continuing training\n",
    "            # model = load_model('neuron_' + str(num_neuron[0]) + '_layer_' + str(num_layer[0]) + '.h5')\n",
    "            \n",
    "            '''history_all[i,j] = '''\n",
    "            model.fit(P_train, F_train, batch_size = batch_how, epochs = epoch_total, verbose = 2, shuffle=False, \n",
    "                                         validation_split=0.0, callbacks=[predictions[k,i,j]]) \n",
    "            # no shuffle for time-based data; no validation, since 7-fold cross-validation already include validaiton; \n",
    "            # callbacks is used for prediction history record; \n",
    "            # no need for history_all, which records the training error history, but we only care about predict error.\n",
    "\n",
    "# record end time\n",
    "endtime = datetime.datetime.now()\n",
    "# print total time\n",
    "print('code runs %d s' % (endtime - starttime).seconds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125f51a-9ed6-42ca-af0b-d5acf70bce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mse history   \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse_pred_per_epoch = np.zeros([folds,epoch_total])\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "layer_this  = num_layer[0]\n",
    "\n",
    "for i in range(folds): # number of folds\n",
    "    for j in range(epoch_total):\n",
    "        mse_pred_per_epoch[i,j] = mse(F_test_rec[0][:][:], predictions[i,neuron_this,layer_this].epoch_predictions[j][:,0])\n",
    "    axes.semilogy(mse_pred_per_epoch[i,:], label='fold: %d | test error' % (i))\n",
    "    axes.legend()\n",
    "    \n",
    "    # find the index of the min value in an array\n",
    "    aaa = mse_pred_per_epoch[i].tolist()\n",
    "    min_value = min(aaa)\n",
    "    min_value_index = aaa.index(min_value)\n",
    "    print('The index of the min value is: %d | The min value is: %f' % (min_value_index, min_value))\n",
    "# axes[0].set_xlim([0,50])\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Mean Square Error (log)')\n",
    "axes.set_title('Neuron:%d, Layer:%d || weight_decay:%.5f || learn_rate:%f || batch_size:%d' % (neuron_this,layer_this, weight_decay, learn_rate,batch_how))\n",
    "# axes.text(165, 0.1, 'elu')\n",
    "\n",
    "# axes.semilogy(history_all[num_neuron[0],num_layer[0]].history['loss'], label='train error')\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c602d-09c3-42b7-85df-311e2391aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check, plot\n",
    "T = 0.3 # period is 0.3s\n",
    "f = 1000 # frequency is 1000Hz\n",
    "t_star = np.arange(0,10000) / f / T \n",
    "fig, axes = plt.subplots(1,1,figsize=(12, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "\n",
    "layer_this  = num_layer[0]\n",
    "\n",
    "# axes.set_ylim([-0.15,0.35])\n",
    "# axes.set_ylim([9.8,10.4])\n",
    "axes.plot(t_star, F_test_rec[0][:,:],label='F_test',color='red', linewidth=3)\n",
    "axes.plot(t_star, predictions[0,neuron_this,layer_this].epoch_predictions[min_value_index][:,0], label='F_pred',color='blue', linewidth=2, linestyle='--')\n",
    "axes.legend()\n",
    "axes.set_xlabel('T$^*$')\n",
    "axes.set_ylabel('CL')\n",
    "axes.set_title('Fold08 Neuron: %d, Layer:%d || Epoch:%d || Mean_error:%.5f' % (neuron_this,layer_this, min_value_index, min_value))\n",
    "fig.savefig('predict_neuron%d_layer%d_fold08_epoch_%d.png' % (neuron_this,layer_this,min_value_index), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82fb21-b712-4b83-8ae6-76572a6b7c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525aa6d-7bea-44c9-8719-1551502567dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_true_no_filter = F_test_rec[0][:,:]\n",
    "CL_predit_no_filter = predictions[0,neuron_this,layer_this].epoch_predictions[min_value_index]#[:,0]\n",
    "\n",
    "t_star = pd.DataFrame(data=t_star).to_numpy() # convert t_start form 1d to 2d\n",
    "predict_CL_no_filter = np.concatenate((t_star, CL_true_no_filter, CL_predit_no_filter), axis=1)\n",
    "\n",
    "predict_no_filter = pd.DataFrame(data=predict_CL_no_filter, columns=['t_star','CL_true_no_filter','CL_predit_no_filter'])\n",
    "predict_no_filter.to_csv('predict_no_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628675b-d41d-4f52-bb2a-e6332e7074f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,5))\n",
    "ax.plot(predict_no_filter[['CL_true_no_filter']].to_numpy()[0:-1,0])\n",
    "ax.plot(predict_no_filter[['CL_predit_no_filter']].to_numpy()[0:-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966374d-eed3-4551-8612-2c2c6363f536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65db913-40f2-4315-b0d9-71e951e04a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('neuron_' + str(num_neuron[0]) + '_layer_' + str(num_layer[0]) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd459e8-35c4-4b9a-bd70-13d35cde8aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdc410-7845-4879-85eb-2cb4ba3e0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create Gif'''\n",
    "# check, plot\n",
    "T = 0.3 # period is 0.3s\n",
    "f = 1000 # frequency is 1000Hz\n",
    "t_star = np.arange(0,10000) / f / T \n",
    "fig, axes = plt.subplots(1,1,figsize=(12, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "layer_this  = num_layer[0]\n",
    "j = 0 # for count only\n",
    "for i in range(0,min_value_index,20):\n",
    "    axes.set_ylim([-1, 3])\n",
    "    axes.plot(t_star, F_test_rec[0][:,:] / shift_for_relu, label='F_test',color='red', linewidth=3)\n",
    "    axes.plot(t_star, predictions[0,neuron_this,layer_this].epoch_predictions[i][:,0] / shift_for_relu, label='F_pred',color='blue', linewidth=2, linestyle='--')\n",
    "    axes.legend()\n",
    "    axes.set_xlabel('T$^*$')\n",
    "    axes.set_ylabel('Plane Normal Force Coefficient')\n",
    "    axes.set_title('Neuron: %d, Layer: %d, Epoch: %d' % (neuron_this,layer_this, i))\n",
    "    fig.savefig('./image_n32_l1/predict_neuron32_layer1_epoch_%d_lift.png' % (i), bbox_inches='tight', dpi=300)\n",
    "    axes.cla()\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b9dbe-2fbb-4dc8-a293-02fbd3df6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Gif\n",
    "image_name = []\n",
    "for i in range(j):\n",
    "    image_name.append('predict_neuron32_layer1_epoch_%d_lift.png' % (i*20))\n",
    "import imageio\n",
    "with imageio.get_writer('./image_n32_l1/mygif_lift.gif', mode='I') as writer:\n",
    "    for filename in image_name:\n",
    "        image = imageio.imread('./image_n32_l1/' +  filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2791c8c-e12c-4e44-bbb6-927509031c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0a024-a568-4891-8f92-501dbeddb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction history\n",
    "import pickle\n",
    "\n",
    "# #Save the variable\n",
    "# pickle.dump(predictions, open(\"predictions.dat\", \"wb\"))\n",
    "# #Load the variable\n",
    "# variable = pickle.load(open(\"predictions.dat\", \"rb\"))\n",
    "\n",
    "for i in num_neuron: # define the neurons\n",
    "    for j in num_layer: # define the hidden layers \n",
    "        for k in range(folds): # start loop for 7 folds cross-validation\n",
    "            pickle.dump(predictions[k,i,j].epoch_predictions, open('F_pred_fold_'+str(k)+'_neuron_'+str(i)+'_layer_'+str(j)+'.dat', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc33a2-d3b4-4d28-870b-6fb48e6abcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "51d70ca6f67856079a32dd433dc7b2f235041bb42b697569d4b18a5049359686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
