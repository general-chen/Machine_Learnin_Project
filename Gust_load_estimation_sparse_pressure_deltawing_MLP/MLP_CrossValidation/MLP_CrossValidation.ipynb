{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc85384-5338-44b5-8cca-0a23ede41570",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This code is an MLP cross-validation for CL estimation\n",
    "- use MLP model\n",
    "- no filter for all CL, CD\n",
    "- bessel filter for CP |  bessel filter; $w_n = 0.01$, the frequence based on Nyquist rate (=sample_freq/2) is: $0.01*1000/2=5$\n",
    "- no standardization; no normalization\n",
    "- with L2\n",
    "- activation func: PReLU\n",
    "- No CP'(t), CP''(t) !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a4dee-08ed-4cc7-97a7-c4aadbccc951",
   "metadata": {},
   "source": [
    "# Define which task to run:\n",
    "- task  = ['predict', 'cross_validation']\n",
    "    - 'cross_validation': for cross validation; has 7 folds\n",
    "    - 'predict': for test using parameters chose by cross validation; has 1 fold --> fold8\n",
    "- force = ['CL', 'CD']\n",
    "- filt  = ['bessel', 'no filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11df159-4433-4a6d-884b-50f11da2a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'cross_validation' \n",
    "force = 'CL'     \n",
    "filt = 'bessel'  # only for cp; no cl or cd filter\n",
    "\n",
    "if task == 'cross_validation':\n",
    "    folds = 7\n",
    "elif task == 'predict':\n",
    "    folds = 1\n",
    "else:\n",
    "    print('Error. Please define your task.') \n",
    "print('Define the task complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e8323d-900e-4a19-a931-e95ad53e4b82",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aad2e3-d740-4c0a-8dd5-b1d89afb08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, Sequential, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from keras.layers import PReLU \n",
    "from keras.models import load_model\n",
    "\n",
    "# for GPU use\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # \"2,3\" if 2nd, 3rd GPU are used (start with 0) \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy.signal import bessel\n",
    "from scipy.signal import filtfilt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472882e-18a5-44f9-817e-ad04a7c516db",
   "metadata": {},
   "source": [
    "# define the font style in the figures\n",
    "- title, label, legend, text, math text\n",
    "- font: Times New Roman\n",
    "- font size: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ca96d-06cc-489b-ba66-bcc321f44bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "mpl.rcParams['font.size']   = 20 # 15\n",
    "\n",
    "mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21548974-bd16-4069-9612-8c5f38db76a3",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab674201-fae0-4446-8418-fc8b41e7a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path\n",
    "data_path = 'gust_dataframe.csv'\n",
    "\n",
    "# read the excel data\n",
    "gust_origin = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3660c-9326-43eb-a986-cf97278989c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gust_origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48e9af-2019-41d3-ad3a-8fe202dbe203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first column as index, i.e. set case_nn as index, for convenience\n",
    "gust_origin.set_index('case_number', inplace=True)\n",
    "print(gust_origin.shape)\n",
    "# check the first 5 columns\n",
    "gust_origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c0516-ad6b-49c0-9e04-fbc4a70b8c26",
   "metadata": {},
   "source": [
    "# filter data\n",
    "- to eliminate the dynamic response from pressure measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca46c3-539b-4355-bf59-d79ffebe6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bessel filter for every column; only filt CP\n",
    "if filt == 'bessel':\n",
    "    \n",
    "    gust_index   = gust_origin.index\n",
    "    gust_column  = gust_origin.columns\n",
    "    gust_no_filter = np.zeros((gust_index.nunique(),len(gust_origin.loc[['case_01']]),len(gust_origin.columns))) # (32,2500,18)\n",
    "    gust_filter    = np.zeros((gust_index.nunique(),len(gust_origin.loc[['case_01']]),len(gust_origin.columns)))\n",
    "    case_all_no = (np.linspace(0,31,32)).astype(int)\n",
    "    b, a = bessel(8, 0.01) # define the bessel filter; 8 is the filter order; 0.01 is the W_n (between 0 to 1)\n",
    "    \n",
    "    for i in case_all_no:      # i is the case number\n",
    "        case_numer = 'case_' + str(i+1).zfill(2)\n",
    "        gust_no_filter[i] = gust_origin.loc[[case_numer]].to_numpy()\n",
    "        for j in range(len(gust_origin.columns)-2):       # j is the CP and CL CD number\n",
    "            gust_filter[i][:,j] = filtfilt(b, a, gust_no_filter[i][:,j]) # bessel filter for cp\n",
    "        gust_filter[i][:,len(gust_origin.columns)-2] = gust_no_filter[i][:,len(gust_origin.columns)-2]  # no filter for CL\n",
    "        gust_filter[i][:,len(gust_origin.columns)-1] = gust_no_filter[i][:,len(gust_origin.columns)-1]  # no filter for CD\n",
    "    gust = pd.DataFrame(data=np.concatenate(gust_filter,axis=0), index=gust_index, columns=gust_column)\n",
    "    \n",
    "elif filt == 'no filter':\n",
    "    gust = gust_origin\n",
    "    \n",
    "else:\n",
    "    print('Error. Please define your filter.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5309f75-f04f-4e5d-b3b1-b768710d9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gust\n",
    "gust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9975d-9530-43b0-8f0b-be7134f8da8a",
   "metadata": {},
   "source": [
    "## check filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfee08-0f29-4cab-9881-f26a15494d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check filter result\n",
    "if filt == 'bessel':\n",
    "    ii = 16 # case to show\n",
    "    case_to_show = 'case_' + str(ii+1).zfill(2)\n",
    "    cp_to_show   = 1\n",
    "    fig,ax = plt.subplots(figsize=(16,5))\n",
    "    ax.plot(gust_origin.loc[[case_to_show]].to_numpy()[:,cp_to_show],label='gust_no_filter')\n",
    "    ax.plot(gust.loc[[case_to_show]].to_numpy()[:,cp_to_show],label='gust_filter')\n",
    "    ax.legend()\n",
    "elif filt == 'no filter':\n",
    "    print('No filter. No compare.')\n",
    "else:\n",
    "    print('Error. Please define your filter.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de407df-aaaf-4880-90e2-1ada3b4fc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gust[['Cp1_t']].to_numpy()[0:2500,0])\n",
    "plt.plot(gust[['CL']].to_numpy()[0:2500,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff2a42-b979-4d2f-93e2-beefaade6147",
   "metadata": {},
   "source": [
    "# retrieve cp cl and cd from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02190f-a0e2-4fdf-8a3b-bf437fdf31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve CP = 16 columns in total\n",
    "# simply drop CL and CD, then the rest is CP\n",
    "CP = gust.drop(['CL','CD'],axis=1, inplace=False)\n",
    "CP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dedc6-1052-4edf-85f2-d196f1386986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve CL and CD\n",
    "CL = gust[['CL']]\n",
    "CD = gust[['CD']]\n",
    "CL.head()\n",
    "CD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e93ee-54ad-45bc-8b16-60c83628b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve for 8 different folds\n",
    "# read the split .txt file; the number means the cases for test\n",
    "split_path = 'delta_wing_32cases_split_random.txt'\n",
    "with open(split_path, 'r') as file1:    \n",
    "    fold_split = file1.read().splitlines()       # split by \\n\n",
    "fold_split = fold_split[1:] # drop the head line\n",
    "for i in range(8):\n",
    "    fold_split[i] = fold_split[i][9:].split()    # split by space; the number starts from 10th character.\n",
    "    for j in range(4):\n",
    "        fold_split[i][j] = int(fold_split[i][j]) # convert string to int\n",
    "fold_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c371b-62bf-4bfc-b466-8c83b9a0f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 32 case number\n",
    "case_all_num = np.arange(gust.index.nunique()) + 1\n",
    "print(case_all_num)\n",
    "print(case_all_num.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8160d8-c789-4114-af55-eb91d37144ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the case number for train and test cases;\n",
    "if task == 'cross_validation':\n",
    "    train_case = [ [0]*24 for _ in range(folds) ] # initialize 2d list; list for 'case_nn'\n",
    "    test_case  = [ [0]*4 for _ in range(folds) ]\n",
    "    # find case number for cross validation folds: fold1~fold7\n",
    "    for i in range(folds): \n",
    "        train_case_temp = np.setdiff1d( case_all_num, np.concatenate((fold_split[i], fold_split[-1]))) \n",
    "        # drop test case and the last one (which is for fold 8 , final test)\n",
    "        test_case_temp  = fold_split[i]\n",
    "\n",
    "        # conbine to 'case_nn' sample for train and test case; prepare for next step\n",
    "        for j in range(len(train_case_temp)):\n",
    "            train_case[i][j] = 'case_' + str(train_case_temp[j]).zfill(2)\n",
    "        for k in range(len(test_case_temp)):\n",
    "            test_case[i][k]  = 'case_' + str(test_case_temp[k]).zfill(2)\n",
    "            \n",
    "elif task == 'predict': \n",
    "    train_case = [ [0]*28 for _ in range(folds) ] # initialize 2d list; list for 'case_nn'\n",
    "    test_case  = [ [0]*4 for _ in range(folds) ]\n",
    "    # find case number for test fold: fold8  \n",
    "    train_case_temp = np.setdiff1d(case_all_num, fold_split[-1])\n",
    "    test_case_temp  = fold_split[-1]\n",
    "    for jj in range(len(train_case_temp)):\n",
    "        train_case[-1][jj] = 'case_' + str(train_case_temp[jj]).zfill(2)\n",
    "    for kk in range(len(test_case_temp)):\n",
    "        test_case[-1][kk]  = 'case_' + str(test_case_temp[kk]).zfill(2)\n",
    "\n",
    "else:\n",
    "    print('Error. Please define your task.')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210977a4-2397-4c01-a2bd-86b7cbeb640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_case[0])\n",
    "print(test_case[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00903cc-e920-4325-b94e-f89cd8a9f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task)\n",
    "print(force)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1975d80-d289-44bd-97c0-a4530a6a751b",
   "metadata": {},
   "source": [
    "#  prepare for train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668a40d-e195-4139-baf7-3692134e6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'cross_validation':\n",
    "    F_train_rec = np.zeros([folds,60000,1]) # 24*2500 = 60000\n",
    "    F_test_rec  = np.zeros([folds,10000,1])  # 4*2500  = 10000\n",
    "    P_train_rec = np.zeros([folds,60000,16])\n",
    "    P_test_rec  = np.zeros([folds,10000,16])\n",
    "\n",
    "    for i in range(folds): # 7 folds for training, the last one is for test, not retrieve here, since this is for training\n",
    "        if force == 'CL':\n",
    "            F_train_rec[i] = CL.loc[train_case[i]].to_numpy()\n",
    "            F_test_rec[i]  = CL.loc[test_case[i]].to_numpy()\n",
    "        elif force == 'CD':\n",
    "            F_train_rec[i] = CD.loc[train_case[i]].to_numpy()\n",
    "            F_test_rec[i]  = CD.loc[test_case[i]].to_numpy()\n",
    "        else:\n",
    "            print('Error. Please define force.')\n",
    "\n",
    "        P_train_rec[i] = CP.loc[train_case[i]].to_numpy()\n",
    "        P_test_rec[i]  = CP.loc[test_case[i]].to_numpy()\n",
    "\n",
    "elif task == 'predict':\n",
    "    F_train_rec = np.zeros([folds,70000,1]) # 28*2500 = 70000\n",
    "    F_test_rec  = np.zeros([folds,10000,1])  # 4*2500  = 10000\n",
    "    P_train_rec = np.zeros([folds,70000,16])\n",
    "    P_test_rec  = np.zeros([folds,10000,16])\n",
    "    \n",
    "    if force == 'CL':\n",
    "        F_train_rec[0] = CL.loc[train_case[0]].to_numpy()\n",
    "        F_test_rec[0]  = CL.loc[test_case[0]].to_numpy()\n",
    "    elif force == 'CD':\n",
    "        F_train_rec[0] = CD.loc[train_case[0]].to_numpy()\n",
    "        F_test_rec[0]  = CD.loc[test_case[0]].to_numpy()\n",
    "    else:\n",
    "        print('Error. Please define force.')\n",
    "\n",
    "    P_train_rec[0] = CP.loc[train_case[0]].to_numpy()\n",
    "    P_test_rec[0]  = CP.loc[test_case[0]].to_numpy()\n",
    "    \n",
    "else:\n",
    "    print('Error. Please define your task.')\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537d8f8-85b4-495f-b60b-f8d787d21a37",
   "metadata": {},
   "source": [
    "# training MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40602d68-68f3-48d0-9ffd-1fdc2ac4149f",
   "metadata": {},
   "source": [
    "## define MLP model\n",
    "- it is a sequential API\n",
    "- we can also use functional API, but here we just use sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e31ba6-d4d6-4fdd-a21e-4f7be7ddc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(input_shape, num_neurons, num_layers, weight_decay, learning_rate):\n",
    "    \"\"\"\n",
    "    Create a Multi-Layer Perceptron (MLP) model.\n",
    "    \n",
    "    :param input_shape: Shape of the input data.\n",
    "    :param num_neurons: Number of neurons in each hidden layer.\n",
    "    :param num_layers: Number of hidden layers.\n",
    "    :param weight_decay: L2 regularization factor.\n",
    "    :param learning_rate: Learning rate for the optimizer.\n",
    "    :return: Compiled MLP model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=(input_shape,)))  \n",
    "\n",
    "    # Hidden layers\n",
    "    for _ in range(num_layers):       \n",
    "        model.add(Dense(num_neurons, kernel_regularizer=regularizers.l2(weight_decay))) \n",
    "        model.add(PReLU())\n",
    "\n",
    "    # Output layer\n",
    "    # output dimension = 1 since it is a regression problem; no activation for output layer\n",
    "    model.add(Dense(1, activation='linear', kernel_regularizer=regularizers.l2(weight_decay)))   \n",
    "\n",
    "    # Compile model\n",
    "    adam = optimizers.Adam(learning_rate=learning_rate)    \n",
    "    model.compile(optimizer=adam, loss='mean_squared_error')\n",
    "    # for regression problems, mean squared error (MSE) is often employed; \n",
    "    # do not use 'accuracy', as this is used for classification problem\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c2f7b-2a0d-4255-9af9-064b14dc2cde",
   "metadata": {},
   "source": [
    "## define callback func\n",
    "- to predict (not validate) using the current trained model on epoch end\n",
    "- we can define the prediction frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37862354-f4ef-45a2-a79f-62e3a24625be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionOnEpochEnd(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, prediction_freq=1, P_test=None):\n",
    "        \"\"\"\n",
    "        Initialize the callback.\n",
    "\n",
    "        :param prediction_freq: Frequency of epochs on which to make predictions.\n",
    "        :param P_test: Test data to predict on.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.prediction_freq = prediction_freq\n",
    "        self.P_test = P_test\n",
    "        self.epoch_predictions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        At the end of each epoch, make predictions if the epoch number is a multiple of the prediction frequency.\n",
    "\n",
    "        :param epoch: The current epoch number.\n",
    "        :param logs: Additional logs.\n",
    "        \"\"\"\n",
    "        if (epoch + 1) % self.prediction_freq == 0:\n",
    "            self.epoch_predictions.append(self.model.predict(self.P_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3443ef-610d-4a23-b70e-1453d12ca4d9",
   "metadata": {},
   "source": [
    "## define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585434b-1d4a-4333-861b-a198700de985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_neuron = [16, 24, 32, 40, 48, 56, 64, 72]\n",
    "num_layer  = [6] # [1,2,3,4,5,6,7,8]\n",
    "epoch_total = 200 \n",
    "weight_decay = 0 # 5e-4 # l2 regularization hyperparameter | no L2, as there is noise in CL\n",
    "learn_rate   = 1e-5 \n",
    "batch_how    = 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3772a3-7070-4d36-aea6-b845f640ca33",
   "metadata": {},
   "source": [
    "## begin training\n",
    "- cross validation is used for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26f1a5-c197-4148-a856-144e631949bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the data\n",
    "# define a dictionary to store the data\n",
    "history_all = {}\n",
    "predictions = {}\n",
    "\n",
    "# record start time\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "for i in num_neuron: # define the neurons\n",
    "    \n",
    "    for j in num_layer: # define the hidden layers\n",
    "        \n",
    "        for k in range(folds): # start loop; if folds=7, then do cross validation; if folds=1, then, do predict\n",
    "            \n",
    "            print('start fold'+str(k+1).zfill(2)+' | layer'+str(j)+' |neuron'+str(i))\n",
    "            \n",
    "            F_train = F_train_rec[k][:,:]   # change to 2d for training\n",
    "            F_test  = F_test_rec[k][:,:]\n",
    "            P_train = P_train_rec[k][:,:]\n",
    "            P_test  = P_test_rec[k][:,:]\n",
    "            '''load data done'''\n",
    "            \n",
    "            # Create MLP model\n",
    "            model = create_mlp_model(input_shape=16, num_neurons=i, num_layers=j, weight_decay=weight_decay, learning_rate=learn_rate)\n",
    "\n",
    "            model.summary()\n",
    "\n",
    "            # Initialize callback\n",
    "            predictions[k,i,j] = PredictionOnEpochEnd(prediction_freq=1, P_test=P_test)  # Predict every 1 epoch, we can use other frequency\n",
    "            \n",
    "            # # load model, only for continuing training\n",
    "            # model = load_model('neuron_' + str(num_neuron[0]) + '_layer_' + str(num_layer[0]) + '.h5')\n",
    "            \n",
    "            '''history_all[i,j] = '''\n",
    "            model.fit(P_train, F_train, batch_size = batch_how, epochs = epoch_total, verbose = 2, shuffle=False, \n",
    "                      validation_split=0.0, callbacks=[predictions[k,i,j]]) \n",
    "            # no shuffle for time-based data; no validation, since 7-fold cross-validation already include validaiton; \n",
    "            # callbacks is used for prediction history record; \n",
    "            # no need for history_all, which records the training error history, but we only care about predict error.\n",
    "\n",
    "# record end time\n",
    "endtime = datetime.datetime.now()\n",
    "# print total time\n",
    "print('code runs %d s' % (endtime - starttime).seconds )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99adbb4d-0451-4455-be7b-8fe835fab3c4",
   "metadata": {},
   "source": [
    "# plot the mse history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125f51a-9ed6-42ca-af0b-d5acf70bce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse_pred_per_epoch = np.zeros([folds,epoch_total])\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "layer_this  = num_layer[0]\n",
    "\n",
    "for i in range(folds): # number of folds\n",
    "    for j in range(epoch_total):\n",
    "        mse_pred_per_epoch[i,j] = mse(F_test_rec[0][:][:], predictions[i,neuron_this,layer_this].epoch_predictions[j][:,0])\n",
    "    axes.semilogy(mse_pred_per_epoch[i,:], label='fold: %d | test error' % (i))\n",
    "    axes.legend()\n",
    "    \n",
    "    # find the index of the min value in an array\n",
    "    aaa = mse_pred_per_epoch[i].tolist()\n",
    "    min_value = min(aaa)\n",
    "    min_value_index = aaa.index(min_value)\n",
    "    print('The index of the min value is: %d | The min value is: %f' % (min_value_index, min_value))\n",
    "# axes[0].set_xlim([0,50])\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Mean Square Error (log)')\n",
    "axes.set_title('Neuron:%d, Layer:%d || weight_decay:%.5f || learn_rate:%f || batch_size:%d' % (neuron_this,layer_this, weight_decay, learn_rate,batch_how))\n",
    "# axes.text(165, 0.1, 'elu')\n",
    "\n",
    "# axes.semilogy(history_all[num_neuron[0],num_layer[0]].history['loss'], label='train error')\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69f04c-2f5a-43b7-9fd0-21f91ea5a614",
   "metadata": {},
   "source": [
    "## check , plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c602d-09c3-42b7-85df-311e2391aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.3 # period is 0.3s\n",
    "f = 1000 # frequency is 1000Hz\n",
    "t_star = np.arange(0,10000) / f / T \n",
    "fig, axes = plt.subplots(1,1,figsize=(12, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "\n",
    "layer_this  = num_layer[0]\n",
    "\n",
    "# axes.set_ylim([-0.15,0.35])\n",
    "# axes.set_ylim([9.8,10.4])\n",
    "axes.plot(t_star, F_test_rec[0][:,:],label='F_test',color='red', linewidth=3)\n",
    "axes.plot(t_star, predictions[0,neuron_this,layer_this].epoch_predictions[min_value_index][:,0], label='F_pred',color='blue', linewidth=2, linestyle='--')\n",
    "axes.legend()\n",
    "axes.set_xlabel('T$^*$')\n",
    "axes.set_ylabel('CL')\n",
    "axes.set_title('Fold08 Neuron: %d, Layer:%d || Epoch:%d || Mean_error:%.5f' % (neuron_this,layer_this, min_value_index, min_value))\n",
    "fig.savefig('predict_neuron%d_layer%d_fold08_epoch_%d.png' % (neuron_this,layer_this,min_value_index), bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82fb21-b712-4b83-8ae6-76572a6b7c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d0b714-c7b7-4517-bde1-57e038717ec6",
   "metadata": {},
   "source": [
    "# save prediction history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0a024-a568-4891-8f92-501dbeddb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# #Save the variable\n",
    "# pickle.dump(predictions, open(\"predictions.dat\", \"wb\"))\n",
    "# #Load the variable\n",
    "# variable = pickle.load(open(\"predictions.dat\", \"rb\"))\n",
    "\n",
    "for i in num_neuron: # define the neurons\n",
    "    for j in num_layer: # define the hidden layers \n",
    "        for k in range(folds): # start loop for 7 folds cross-validation\n",
    "            pickle.dump(predictions[k,i,j].epoch_predictions, open('F_pred_fold_'+str(k)+'_neuron_'+str(i)+'_layer_'+str(j)+'.dat', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92519bb9-8a68-4ff7-b409-d63abebd5a9b",
   "metadata": {},
   "source": [
    "# save dataset to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525aa6d-7bea-44c9-8719-1551502567dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_true_no_filter = F_test_rec[0][:,:]\n",
    "CL_predit_no_filter = predictions[0,neuron_this,layer_this].epoch_predictions[min_value_index]#[:,0]\n",
    "\n",
    "t_star = pd.DataFrame(data=t_star).to_numpy() # convert t_start form 1d to 2d\n",
    "predict_CL_no_filter = np.concatenate((t_star, CL_true_no_filter, CL_predit_no_filter), axis=1)\n",
    "\n",
    "predict_no_filter = pd.DataFrame(data=predict_CL_no_filter, columns=['t_star','CL_true_no_filter','CL_predit_no_filter'])\n",
    "predict_no_filter.to_csv('predict_no_filter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ed2da-40a2-4094-aba9-82bd39da7c6d",
   "metadata": {},
   "source": [
    "## plot using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628675b-d41d-4f52-bb2a-e6332e7074f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,5))\n",
    "ax.plot(predict_no_filter[['CL_true_no_filter']].to_numpy()[0:-1,0])\n",
    "ax.plot(predict_no_filter[['CL_predit_no_filter']].to_numpy()[0:-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b027a-0bb3-436a-a455-b70039d161f7",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65db913-40f2-4315-b0d9-71e951e04a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('neuron_' + str(num_neuron[0]) + '_layer_' + str(num_layer[0]) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847f49b-5964-4d34-900f-2eef44f1295a",
   "metadata": {},
   "source": [
    "# create gif to show the convergence history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdc410-7845-4879-85eb-2cb4ba3e0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create Gif'''\n",
    "# check, plot\n",
    "T = 0.3 # period is 0.3s\n",
    "f = 1000 # frequency is 1000Hz\n",
    "t_star = np.arange(0,10000) / f / T \n",
    "fig, axes = plt.subplots(1,1,figsize=(12, 5))\n",
    "\n",
    "neuron_this = num_neuron[0]\n",
    "layer_this  = num_layer[0]\n",
    "j = 0 # for count only\n",
    "for i in range(0,min_value_index,20):\n",
    "    axes.set_ylim([-1, 3])\n",
    "    axes.plot(t_star, F_test_rec[0][:,:] / shift_for_relu, label='F_test',color='red', linewidth=3)\n",
    "    axes.plot(t_star, predictions[0,neuron_this,layer_this].epoch_predictions[i][:,0] / shift_for_relu, label='F_pred',color='blue', linewidth=2, linestyle='--')\n",
    "    axes.legend()\n",
    "    axes.set_xlabel('T$^*$')\n",
    "    axes.set_ylabel('Plane Normal Force Coefficient')\n",
    "    axes.set_title('Neuron: %d, Layer: %d, Epoch: %d' % (neuron_this,layer_this, i))\n",
    "    fig.savefig('./image_n32_l1/predict_neuron32_layer1_epoch_%d_lift.png' % (i), bbox_inches='tight', dpi=300)\n",
    "    axes.cla()\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b9dbe-2fbb-4dc8-a293-02fbd3df6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Gif\n",
    "image_name = []\n",
    "for i in range(j):\n",
    "    image_name.append('predict_neuron32_layer1_epoch_%d_lift.png' % (i*20))\n",
    "import imageio\n",
    "with imageio.get_writer('./image_n32_l1/mygif_lift.gif', mode='I') as writer:\n",
    "    for filename in image_name:\n",
    "        image = imageio.imread('./image_n32_l1/' +  filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc33a2-d3b4-4d28-870b-6fb48e6abcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "51d70ca6f67856079a32dd433dc7b2f235041bb42b697569d4b18a5049359686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
